{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Pipeline Details\n",
    "\n",
    "This notebook goes into detail about the stages of the video pipeline in the base overlay and is written for people who want to create and integrate their own video IP. For most regular input and output use cases the high level wrappers of `HDMIIn` and `HDMIOut` should be used.\n",
    "\n",
    "Both the input and output pipelines in the base overlay consist of four stages, an HDMI frontend, a colorspace converter, a pixel format converter, and the video DMA. For the input the stages are arranged Frontend -> Colorspace Converter -> Pixel Format -> VDMA with the order reversed for the output side. The aim of this notebook is to give you enough information to use each stage separately and be able to modify the pipeline for your own ends.\n",
    "\n",
    "Before exploring the pipeline we'll import the entire pynq.lib.video module where all classes relating to the pipelines live. We'll also load the base overlay to serve as an example.\n",
    "\n",
    "The following table shows the IP responsible for each stage in the base overlay which will be referenced throughout the rest of the notebook\n",
    "\n",
    "|Stage             | Input IP                               | Output IP                          |\n",
    "|------------------|:---------------------------------------|:-----------------------------------|\n",
    "|Frontend (Timing) |`video/hdmi_in/frontend/vtc_in`         |`video/hdmi_out/frontend/vtc_out`   |\n",
    "|Frontend (Other)  |`video/hdmi_in/frontend/axi_gpio_hdmiin`|`video/hdmi_out/frontend/axi_dynclk`|\n",
    "|Colour Space      |`video/hdmi_in/color_convert`           |`video/hdmi_out/color_convert`      |\n",
    "|Pixel Format      |`video/hdmi_in/pixel_pack`              |`video/hdmi_outpixel_unpack`        |\n",
    "|VDMA              |`video/axi_vdma`                        |`video/axi_vdam`                    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%pybind11/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pynq.overlays.base import BaseOverlay\n",
    "from pynq.lib.video import *\n",
    "import asyncio\n",
    "import time\n",
    "\n",
    "base = BaseOverlay(\"base.bit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HDMI Frontend\n",
    "\n",
    "The HDMI frontend modules wrap all of the clock and timing logic. The HDMI input frontend can be used independently from the rest of the pipeline by accessing its driver from the base overlay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Resolution not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m default_mode \u001b[38;5;241m=\u001b[39m VideoMode(\u001b[38;5;241m1920\u001b[39m, \u001b[38;5;241m1080\u001b[39m, \u001b[38;5;241m24\u001b[39m)\n\u001b[1;32m     13\u001b[0m hdmi_out\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m=\u001b[39m default_mode\n\u001b[0;32m---> 14\u001b[0m \u001b[43mhdmi_out\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Start VDMA channels\u001b[39;00m\n\u001b[1;32m     18\u001b[0m vdma\u001b[38;5;241m.\u001b[39mreadchannel\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m=\u001b[39m default_mode\n",
      "File \u001b[0;32m/usr/local/share/pynq-venv/lib/python3.10/site-packages/pynq/lib/video/xilinx_hdmi.py:139\u001b[0m, in \u001b[0;36mHdmiTxSs.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m frequency \u001b[38;5;241m=\u001b[39m _hdmi_lib\u001b[38;5;241m.\u001b[39mHdmiTx_set_format(\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\u001b[38;5;241m.\u001b[39mwidth, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\u001b[38;5;241m.\u001b[39mheight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\u001b[38;5;241m.\u001b[39mfps\n\u001b[1;32m    137\u001b[0m )\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m frequency \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResolution not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m frequency \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not set PHY clock\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Resolution not supported"
     ]
    }
   ],
   "source": [
    "hdmi_in = base.video.hdmi_in.frontend\n",
    "hdmi_out = base.video.hdmi_out.frontend\n",
    "vdma = base.video.axi_vdma\n",
    "\n",
    "hdmi_in.start()\n",
    "\n",
    "# Ensure a valid video mode is detected\n",
    "if hdmi_in.mode is None:\n",
    "    raise RuntimeError(\"No valid HDMI input detected. Please check the HDMI connection.\")\n",
    "\n",
    "# Configure HDMI output with the detected input mode\n",
    "default_mode = VideoMode(1920, 1080, 24, fps=60)\n",
    "hdmi_out.mode = default_mode\n",
    "hdmi_out.start()\n",
    "\n",
    "\n",
    "# Start VDMA channels\n",
    "vdma.readchannel.mode = default_mode\n",
    "vdma.readchannel.start()\n",
    "vdma.writechannel.mode = default_mode\n",
    "vdma.writechannel.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the device will signal to the computer that a monitor is connected. Starting the frontend will wait attempt to detect the video mode, blocking until a lock can be achieved. Once the frontend is started the video mode will be available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [149]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Asynchronously read a frame from VDMA read channel\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     frame \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m vdma\u001b[38;5;241m.\u001b[39mreadchannel\u001b[38;5;241m.\u001b[39mreadframe_async()\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Directly write the frame to VDMA write channel without modification\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m vdma\u001b[38;5;241m.\u001b[39mwritechannel\u001b[38;5;241m.\u001b[39mwriteframe_async(frame)\n",
      "File \u001b[0;32m/usr/local/share/pynq-venv/lib/python3.10/site-packages/pynq/lib/video/dma.py:197\u001b[0m, in \u001b[0;36mAxiVDMA.S2MMChannel.readframe_async\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDMA channel not started\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mmio\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m0x34\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0x1000\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 197\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interrupt\u001b[38;5;241m.\u001b[39mwait()\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mmio\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;241m0x34\u001b[39m, \u001b[38;5;241m0x1000\u001b[39m)\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_readframe_internal()\n",
      "File \u001b[0;32m/usr/local/share/pynq-venv/lib/python3.10/site-packages/pynq/interrupt.py:85\u001b[0m, in \u001b[0;36mInterrupt.wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m     parent\u001b[38;5;241m.\u001b[39madd_event(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumber)\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwaiting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent\u001b[38;5;241m.\u001b[39mwait()\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwaiting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/asyncio/locks.py:214\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_waiters\u001b[38;5;241m.\u001b[39mappend(fut)\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 214\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m fut\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.10/asyncio/futures.py:284\u001b[0m, in \u001b[0;36mFuture.__await__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_asyncio_future_blocking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m  \u001b[38;5;66;03m# This tells Task to wait for completion.\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mawait wasn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt used with future\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/asyncio/tasks.py:304\u001b[0m, in \u001b[0;36mTask.__wakeup\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m         \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__step(exc)\n",
      "File \u001b[0;32m/usr/lib/python3.10/asyncio/futures.py:196\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m _CANCELLED:\n\u001b[1;32m    195\u001b[0m     exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_cancelled_error()\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m!=\u001b[39m _FINISHED:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mInvalidStateError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResult is not ready.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mCancelledError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # Asynchronously read a frame from VDMA read channel\n",
    "    frame = await vdma.readchannel.readframe_async()\n",
    "\n",
    "    # Directly write the frame to VDMA write channel without modification\n",
    "    await vdma.writechannel.writeframe_async(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Video mode not set, channel not started",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [110]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mhdmi_in\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m hdmi_in\u001b[38;5;241m.\u001b[39mmode\n",
      "File \u001b[0;32m/usr/local/share/pynq-venv/lib/python3.10/site-packages/pynq/lib/video/hierarchies.py:93\u001b[0m, in \u001b[0;36mVideoIn.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstart\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;124;03m\"\"\"Start the pipeline\"\"\"\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_vdma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadchannel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopcontextmanager()\n",
      "File \u001b[0;32m/usr/local/share/pynq-venv/lib/python3.10/site-packages/pynq/lib/video/dma.py:275\u001b[0m, in \u001b[0;36mAxiVDMA.S2MMChannel.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;124;03m\"\"\"Start the DMA. The mode must be set prior to this being called\"\"\"\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode:\n\u001b[0;32m--> 275\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVideo mode not set, channel not started\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdesiredframe \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache \u001b[38;5;241m=\u001b[39m _FrameCache(\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory, cacheable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcacheable_frames\n\u001b[1;32m    279\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Video mode not set, channel not started"
     ]
    }
   ],
   "source": [
    "hdmi_in.start()\n",
    "hdmi_in.mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The HDMI output frontend can be accessed in a similar way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the mode must be set prior to starting the output. In this case we are just going to use the same mode as the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdmi_out.start()\n",
    "hdmi_out.mode = hdmi_in.mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that nothing will be displayed on the screen as no video data is currently being send."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colorspace conversion\n",
    "\n",
    "The colorspace converter operates on each pixel independently using a 3x4 matrix to transform the pixels. The converter is programmed with a list of twelve coefficients in the folling order:\n",
    "\n",
    "|     |in1 |in2 |in3 | 1  |\n",
    "|-----|----|----|----|----|\n",
    "|out1 |c1  |c2  |c3  |c10 |\n",
    "|out2 |c4  |c5  |c6  |c11 |\n",
    "|out3 |c7  |c8  |c9  |c12 |\n",
    "\n",
    "Each coefficient should be a floating point number between -2 and +2.\n",
    "\n",
    "The pixels to and from the HDMI frontends are in BGR order so a list of coefficients to convert from the input format to RGB would be:\n",
    "\n",
    "    [0, 0, 1,\n",
    "     0, 1, 0,\n",
    "     1, 0, 0,\n",
    "     0, 0, 0]\n",
    "\n",
    "reversing the order of the pixels and not adding any bias.\n",
    "\n",
    "The driver for the colorspace converters has a single property that contains the list of coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colorspace_in = base.video.hdmi_in.color_convert\n",
    "colorspace_out = base.video.hdmi_out.color_convert\n",
    "\n",
    "bgr2rgb = [0, 0, 1,\n",
    "           0, 1, 0, \n",
    "           1, 0, 0,\n",
    "           0, 0, 0]\n",
    "\n",
    "colorspace_in.colorspace = bgr2rgb\n",
    "colorspace_out.colorspace = bgr2rgb\n",
    "\n",
    "colorspace_in.colorspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pixel format conversion\n",
    "\n",
    "The pixel format converters convert between the 24-bit signal used by the HDMI frontends and the colorspace converters to either an 8, 24, or 32 bit signal. 24-bit mode passes the input straight through, 32-bit pads the additional pixel with 0 and 8-bit mode selects the first channel in the pixel. This is exposed by a single property to set or get the number of bits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixel_in = base.video.hdmi_in.pixel_pack\n",
    "pixel_out = base.video.hdmi_out.pixel_unpack\n",
    "\n",
    "pixel_in.bits_per_pixel = 8\n",
    "pixel_out.bits_per_pixel = 8\n",
    "\n",
    "pixel_in.bits_per_pixel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video DMA\n",
    "\n",
    "The final element in the pipeline is the video DMA which transfers video frames to and from memory. The VDMA consists of two channels, one for each direction which operate completely independently. To use a channel its mode must be set prior to start being called. After the DMA is started `readframe` and `writeframe` transfer frames. Frames are only transferred once with the call blocking if necessary. `asyncio` coroutines are available as `readframe_async` and `writeframe_async` which yield instead of blocking. A frame of the size of the output can be retrieved from the VDMA by calling `writechannel.newframe()`. This frame is not guaranteed to be initialised to blank so should be completely written before being handed back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "inputmode = hdmi_in.mode\n",
    "hdmi_out = base.video.hdmi_out.frontend\n",
    "\n",
    "hdmi_out.start()\n",
    "\n",
    "framemode = VideoMode(inputmode.width, inputmode.height, 8)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    frame = vdma.readchannel.readframe()\n",
    "    vdma.writechannel.writeframe(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'AxiVDMA' object has no attribute 'sendchannel'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [85]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun_passthrough\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [84]\u001b[0m, in \u001b[0;36mrun_passthrough\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      6\u001b[0m     tasks \u001b[38;5;241m=\u001b[39m [readframes(), writeframes()]\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Run both tasks concurrently\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVDMA HDMI passthrough stopped.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/share/pynq-venv/lib/python3.10/site-packages/nest_asyncio.py:89\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     88\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvent loop stopped before Future completed.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/asyncio/tasks.py:232\u001b[0m, in \u001b[0;36mTask.__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    230\u001b[0m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mcoro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    234\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n",
      "Input \u001b[0;32mIn [82]\u001b[0m, in \u001b[0;36mreadframes\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m      6\u001b[0m     frame \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m hdmi_in\u001b[38;5;241m.\u001b[39mreadframe_async()  \u001b[38;5;66;03m# Asynchronous frame read\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mvdma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msendchannel\u001b[49m\u001b[38;5;241m.\u001b[39mtransfer(frame)         \u001b[38;5;66;03m# Send frame to VDMA write channel\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m vdma\u001b[38;5;241m.\u001b[39msendchannel\u001b[38;5;241m.\u001b[39mwait_async()      \u001b[38;5;66;03m# Wait for the transfer to complete\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     frame\u001b[38;5;241m.\u001b[39mfreebuffer()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AxiVDMA' object has no attribute 'sendchannel'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, because we are only using 8 bits per pixel, only the red channel is read and displayed.\n",
    "\n",
    "The two channels can be tied together which will ensure that the input is always mirrored to the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "vdma.readchannel.tie(vdma.writechannel)\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frame Ownership\n",
    "\n",
    "The VDMA driver has a strict method of frame ownership. Any frames returned by `readframe` or `newframe` are owned by the user and should be destroyed by the user when no longer needed by calling `frame.freebuffer()`. Frames handed back to the VDMA with `writeframe` are no longer owned by the user and should not be touched - the data may disappear at any time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning up\n",
    "\n",
    "It is vital to stop the VDMA before reprogramming the bitstream otherwise the memory system of the chip can be placed into an undefined state. If the monitor does not power on when starting the VDMA this is the likely cause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdma.readchannel.stop()\n",
    "vdma.writechannel.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdmi_in.stop()\n",
    "hdmi_out.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
